{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwA7QNfuwppQ"
      },
      "outputs": [],
      "source": [
        "import sklearn, os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF0zisiPwwe-",
        "outputId": "48e8ca8c-eac2-4b6a-f327-f77f5ec6e426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lNY1L2yhw7RD",
        "outputId": "fe463fbc-ad68-4fa6-dc91-e9a5ac02851e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e38f0bcde512>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "QHwKWZjLxVay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "MqWbQ4xaxYeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vmFFzWLTxamo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].unique()"
      ],
      "metadata": {
        "id": "PsjELomDxd-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1ecv8v61xiIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_classes = [\n",
        "    'DDoS-RSTFINFlood', 'DDoS-PSHACK_Flood', 'DDoS-SYN_Flood',\n",
        "    'DDoS-UDP_Flood', 'DDoS-TCP_Flood', 'DDoS-ICMP_Flood',\n",
        "    'DDoS-SynonymousIP_Flood', 'DDoS-ACK_Fragmentation',\n",
        "    'DDoS-UDP_Fragmentation', 'DDoS-ICMP_Fragmentation',\n",
        "    'DDoS-SlowLoris', 'DDoS-HTTP_Flood','BenignTraffic'\n",
        "]"
      ],
      "metadata": {
        "id": "3pVXmfWyxnbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ddos = df[df['label'].isin(filtered_classes)]"
      ],
      "metadata": {
        "id": "B9wwKVwFx2EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ddos"
      ],
      "metadata": {
        "id": "UpOvuL6Zx5SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ddos.isnull().sum()"
      ],
      "metadata": {
        "id": "VZ6RBhZmx7U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ddos['label'].unique()"
      ],
      "metadata": {
        "id": "2_KezMJux-91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ddos.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "fd2LTEbNyGvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming scaled_df is your DataFrame containing scaled data\n",
        "# Compute the correlation matrix\n",
        "df_features= df_ddos.drop('label', axis=1)\n",
        "\n",
        "corr_matrix = df_features.corr()\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Draw the heatmap with seaborn using a different color map\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='viridis', fmt='.2f', linewidths=1, linecolor='white')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Correlation Matrix', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DSpZYxqiyJIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df_ddos is your DataFrame containing the data\n",
        "# Compute the correlation matrix, excluding the label column\n",
        "df_features = df_ddos.drop('label', axis=1)\n",
        "corr_matrix = df_features.corr()\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Draw the heatmap with seaborn using a different color map\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='viridis', fmt='.2f', annot_kws={\"size\": 8}, linewidths=1, linecolor='white')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Correlation Matrix', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N62eQgAYn-fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = ['ece_flag_number', 'cwr_flag_number', 'Telnet','SMTP','SSH','IRC','UDP']\n",
        "\n",
        "# Drop the specified columns\n",
        "df_cleaned = df_ddos.drop(columns=columns_to_drop)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(\"DataFrame after dropping columns:\")\n",
        "print(df_cleaned.head())"
      ],
      "metadata": {
        "id": "x6qQF-QkyRYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.shape\n"
      ],
      "metadata": {
        "id": "tDrluhKwyYUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "dAyareU7yeyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned"
      ],
      "metadata": {
        "id": "He0SJ201zEHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df_cleaned['label'].value_counts()\n",
        "\n",
        "# Create a bar plot using Seaborn\n",
        "plt.figure(figsize=(15, 8))  # Increased figure size for better readability\n",
        "ax = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')  # Changed palette for better contrast\n",
        "plt.title('Distribution of Attack')\n",
        "plt.xlabel('Network Traffic Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)  # Changed rotation to 90 degrees to prevent overlapping\n",
        "\n",
        "# Set a variable for the maximum height of the y-axis, slightly more than the highest bar\n",
        "max_height = max(class_counts.values) * 1.1\n",
        "plt.ylim(0, max_height)  # Set the y-axis limit to accommodate the percentage annotations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "FT83VePmZRXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming 'label' is the target column\n",
        "X1111 = df_cleaned.drop('label', axis=1)\n",
        "y1111 = df_cleaned['label']\n",
        "\n",
        "\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled11, y_resampled11 = smote.fit_resample(X1111, y1111)\n",
        "\n",
        "# Merge resampled features and labels into a new DataFrame\n",
        "df_resampled11 = pd.concat([pd.DataFrame(X_resampled11, columns=X1111.columns), pd.Series(y_resampled11, name='label')], axis=1)"
      ],
      "metadata": {
        "id": "PWKtxRmAbfof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df_resampled11['label'].value_counts()\n",
        "\n",
        "# Create a bar plot using Seaborn\n",
        "plt.figure(figsize=(15, 8))  # Increased figure size for better readability\n",
        "ax = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')  # Changed palette for better contrast\n",
        "plt.title('Distribution of Attack')\n",
        "plt.xlabel('Network Traffic Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)  # Changed rotation to 90 degrees to prevent overlapping\n",
        "\n",
        "# Set a variable for the maximum height of the y-axis, slightly more than the highest bar\n",
        "max_height = max(class_counts.values) * 1.1\n",
        "plt.ylim(0, max_height)  # Set the y-axis limit to accommodate the percentage annotations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "OZt6KJmscDqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.isnull().sum()"
      ],
      "metadata": {
        "id": "EecnkYAK0eaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.to_csv('only_ddos_data.csv',index=False)"
      ],
      "metadata": {
        "id": "XAltaDcN0iDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_only_ddos = pd.read_csv(\"only_ddos_data.csv\")\n",
        "df_only_ddos"
      ],
      "metadata": {
        "id": "QH-lTQ8F0zE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming 'label' is the target column\n",
        "X = df_only_ddos.drop('label', axis=1)\n",
        "y = df_only_ddos['label']\n",
        "\n",
        "\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Merge resampled features and labels into a new DataFrame\n",
        "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='label')], axis=1)"
      ],
      "metadata": {
        "id": "ZI6BqFp602_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled.to_csv('resampled.csv',index = False)"
      ],
      "metadata": {
        "id": "hUcGFcbL070d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_res = pd.read_csv('resampled.csv')"
      ],
      "metadata": {
        "id": "1-weNd_l1LwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "QwPR-FN_1SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_res.drop('label', axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaled_features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
        "scaled_df = pd.concat([scaled_features, df_res['label']], axis=1)\n"
      ],
      "metadata": {
        "id": "80nSoWj51X6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.isnull().sum()"
      ],
      "metadata": {
        "id": "no3lSYs01av1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.info()"
      ],
      "metadata": {
        "id": "Wgtttk6G1gIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the LabelEncoder object\n",
        "enc = LabelEncoder()\n",
        "\n",
        "# Apply the encoding to the \"Accessible\" column\n",
        "scaled_df['label_encoder'] = enc.fit_transform(scaled_df['label'])"
      ],
      "metadata": {
        "id": "0LkEKdhC1mg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.info()"
      ],
      "metadata": {
        "id": "ZW6qtAd818LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.columns"
      ],
      "metadata": {
        "id": "kMeE-DXn1_aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df_drop_label=scaled_df.drop(['label'],axis=1)"
      ],
      "metadata": {
        "id": "Hd4tqD1x23zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df_drop_label.isnull().sum()"
      ],
      "metadata": {
        "id": "YsF4v-JF3AEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df_drop_label.info()"
      ],
      "metadata": {
        "id": "X0CUQJh43DWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df_drop_label['label_encoder'].unique()"
      ],
      "metadata": {
        "id": "p_YQilDs3GHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df['label'].unique()"
      ],
      "metadata": {
        "id": "JP4-Y3lw3X9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled_pca=scaled_df_drop_label.drop('label_encoder', axis=1)\n",
        "Y_scaled_pca=scaled_df_drop_label['label_encoder']"
      ],
      "metadata": {
        "id": "YyXXZEiq4oq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_features=X_scaled_pca.T\n",
        "covariance_matrix= np.cov(PCA_features)\n",
        "covariance_matrix"
      ],
      "metadata": {
        "id": "ESsZC-rV4pW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, vectors = np.linalg.eig(covariance_matrix)"
      ],
      "metadata": {
        "id": "S16rK9n_5Wxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "id": "f-UyfuTM5b0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors.shape"
      ],
      "metadata": {
        "id": "IWdtre215fBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_variance = []\n",
        "for i in range(len(values)):\n",
        "  percentage_variance.append(values[i]/np.sum(values))\n",
        "percentage_variance"
      ],
      "metadata": {
        "id": "L9fVbhmE5i5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(range(1, len(percentage_variance) + 1)), y=percentage_variance, color='skyblue')\n",
        "plt.title('Percentage Variance Explained by Principal Components', fontsize=16)\n",
        "plt.xlabel('Principal Component', fontsize=12)\n",
        "plt.ylabel('Percentage Variance (%)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Foz978od5k-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "projected_1 = X_scaled_pca.dot(vectors.T[0])\n",
        "projected_2 = X_scaled_pca.dot(vectors.T[1])\n",
        "projected_3 = X_scaled_pca.dot(vectors.T[2])\n",
        "\n",
        "\n",
        "\n",
        "result_pca = pd.DataFrame(projected_1, columns= ['PC1'])\n",
        "result_pca['PC2'] = projected_2\n",
        "result_pca['PC3'] = projected_3\n",
        "\n",
        "\n",
        "\n",
        "result_pca['label']= Y_scaled_pca\n",
        "result_pca"
      ],
      "metadata": {
        "id": "1GZhbQxB5qdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_pca.isnull().sum()"
      ],
      "metadata": {
        "id": "hODxEVOS615O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca_heatmap= result_pca[['PC1','PC2','PC3']]\n",
        "sns.heatmap(X_pca_heatmap.corr(), annot=True)"
      ],
      "metadata": {
        "id": "xWxoqxIw64lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = result_pca['label'].value_counts()\n",
        "\n",
        "# Create a bar plot using Seaborn\n",
        "plt.figure(figsize=(15, 8))  # Increased figure size for better readability\n",
        "ax = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')  # Changed palette for better contrast\n",
        "plt.title('Distribution of Attack')\n",
        "plt.xlabel('Network Traffic Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)  # Changed rotation to 90 degrees to prevent overlapping\n",
        "\n",
        "# Set a variable for the maximum height of the y-axis, slightly more than the highest bar\n",
        "max_height = max(class_counts.values) * 1.1\n",
        "plt.ylim(0, max_height)  # Set the y-axis limit to accommodate the percentage annotations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Tw0OlSNv7B4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier with optimized parameters\n",
        "rf_classifier = RandomForestClassifier(n_estimators=30, max_depth=10, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(rf_classifier, 'rf_model.pkl')\n",
        "model_size = os.path.getsize('rf_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Random Forest', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ocr41ZbW7Qee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize KNN classifier (you can specify the number of neighbors, e.g., n_neighbors=5)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate model size (size of the training data)\n",
        "train_data_size = (X_train.memory_usage(deep=True).sum() + y_train.memory_usage(deep=True)) / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size (Training Data Size): {train_data_size:.2f} MB')\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of KNN', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FjHWAR337aDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm scikit-learn\n"
      ],
      "metadata": {
        "id": "astDxQCm7yUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'label' is your target variable and the rest are features\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create LightGBM dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# Define parameters\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',  # Use 'multiclass' for multi-class classification\n",
        "    'num_class': len(Y.unique()),  # Number of classes\n",
        "    'metric': 'multi_logloss',  # Use 'multi_logloss' for multi-class classification\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9\n",
        "}\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "bst = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[train_data, test_data],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        ")\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "bst.save_model('lightgbm_model.txt')\n",
        "model_size = os.path.getsize('lightgbm_model.txt')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Predict on the test set\n",
        "start_pred_time = time.time()\n",
        "y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "y_pred = [np.argmax(x) for x in y_pred_prob]  # For multiclass classification\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(classification_rep)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of LightGBM', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DIXH9Eme8TEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(logreg_classifier, 'logreg_model.pkl')\n",
        "model_size = os.path.getsize('logreg_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Make predictions on the test set\n",
        "start_pred_time = time.time()\n",
        "y_pred = logreg_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of LR', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uZmQif658cFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(dt_classifier, 'dt_model.pkl')\n",
        "model_size = os.path.getsize('dt_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Decision Tree', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IoWjRwxJ9LuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKhdUjXnGIYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = result_pca.drop('label', axis=1)\n",
        "Y = result_pca['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Naive Bayes classifier (Gaussian Naive Bayes for continuous features)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(nb_classifier, 'nb_model.pkl')\n",
        "model_size = os.path.getsize('nb_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Naive Bayes', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uW0dYPDV-tnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X = scaled_df_drop_label.drop('label_encoder', axis=1)\n",
        "y = scaled_df_drop_label['label_encoder']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve feature importances from the trained model\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance scores\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort features by importance (descending order)\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plotting feature importances\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Feature Importance - Random Forest', fontsize=14)\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display most important features at the top\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4fcI0vpx_ElI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = ['IAT','Header_Length','urg_count','label_encoder']\n",
        "rf_scaled_df= scaled_df_drop_label[selected_features]"
      ],
      "metadata": {
        "id": "An7S-pbWASc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_scaled_df"
      ],
      "metadata": {
        "id": "DUH_rQV7Awzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_rf_scaled_df=rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y_rf_scaled_df=rf_scaled_df['label_encoder']\n",
        "X_rf_scaled_df"
      ],
      "metadata": {
        "id": "uurn9LcoAxRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(X_rf_scaled_df.corr(), annot=True)"
      ],
      "metadata": {
        "id": "dmhXhrR0BSRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = rf_scaled_df['label_encoder'].value_counts()\n",
        "\n",
        "# Create a bar plot using Seaborn\n",
        "plt.figure(figsize=(15, 8))  # Increased figure size for better readability\n",
        "ax = sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')  # Changed palette for better contrast\n",
        "plt.title('Distribution of Attack')\n",
        "plt.xlabel('Network Traffic Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)  # Changed rotation to 90 degrees to prevent overlapping\n",
        "\n",
        "# Set a variable for the maximum height of the y-axis, slightly more than the highest bar\n",
        "max_height = max(class_counts.values) * 1.1\n",
        "plt.ylim(0, max_height)  # Set the y-axis limit to accommodate the percentage annotations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ORW9oR71BT0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y = rf_scaled_df['label_encoder']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier with optimized parameters\n",
        "rf_classifier = RandomForestClassifier(n_estimators=30, max_depth=10, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(rf_classifier, 'rf_model.pkl')\n",
        "model_size = os.path.getsize('rf_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Random Forest', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "krJJJIcZB2l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y = rf_scaled_df['label_encoder']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize KNN classifier (you can specify the number of neighbors, e.g., n_neighbors=5)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate model size (size of the training data)\n",
        "train_data_size = (X_train.memory_usage(deep=True).sum() + y_train.memory_usage(deep=True)) / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size (Training Data Size): {train_data_size:.2f} MB')\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of KNN', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PPXzoL40CfVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y = rf_scaled_df['label_encoder']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(logreg_classifier, 'logreg_model.pkl')\n",
        "model_size = os.path.getsize('logreg_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Make predictions on the test set\n",
        "start_pred_time = time.time()\n",
        "y_pred = logreg_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of LR', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hi0wWY22EfwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y = rf_scaled_df['label_encoder']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(dt_classifier, 'dt_model.pkl')\n",
        "model_size = os.path.getsize('dt_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Decision Tree', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "smJ8G8_qGLFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import joblib\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "# Assuming X contains input features and Y contains target labels\n",
        "# Split the data into training and testing sets\n",
        "X = rf_scaled_df.drop('label_encoder', axis=1)\n",
        "Y = rf_scaled_df['label_encoder']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Naive Bayes classifier (Gaussian Naive Bayes for continuous features)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Measure training time\n",
        "start_train_time = time.time()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "end_train_time = time.time()\n",
        "training_time = end_train_time - start_train_time\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(nb_classifier, 'nb_model.pkl')\n",
        "model_size = os.path.getsize('nb_model.pkl')\n",
        "\n",
        "# Measure memory usage\n",
        "process = psutil.Process(os.getpid())\n",
        "memory_usage = process.memory_info().rss / 1024 ** 2  # Convert bytes to megabytes\n",
        "\n",
        "# Measure prediction time\n",
        "start_pred_time = time.time()\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "end_pred_time = time.time()\n",
        "prediction_time = end_pred_time - start_pred_time\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f'Training Time: {training_time:.4f} seconds')\n",
        "print(f'Model Size: {model_size / 1024:.2f} KB')  # Convert bytes to kilobytes\n",
        "print(f'Memory Usage: {memory_usage:.2f} MB')\n",
        "print(f'Prediction Time: {prediction_time:.4f} seconds')\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix of Naive Bayes', fontsize=16)\n",
        "plt.xlabel('Predicted Labels', fontsize=12)\n",
        "plt.ylabel('True Labels', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-SvkSUz7GYBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}